{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EinsteinCovidDataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOg/fQm8SHrRnP1tlD7QM9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vix993/Kunumi_Workshop_Covid19/blob/main/EinsteinCovidDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVhOc1bsSZTH"
      },
      "source": [
        "# Import pertinent Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZsrXPjI_peW",
        "outputId": "34206214-d470-42c6-9874-3354c42bc330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install scipy\n",
        "!pip install matplotlib\n",
        "!pip install sweetviz\n",
        "!pip install sklearn\n",
        "!pip install seaborn\n",
        "!pip install imblearn\n",
        "!pip install statsmodels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Collecting sweetviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c1/e15ac0b39997c0680620d8274a2a7d41730968d5c3958f80bb80127ceb5f/sweetviz-1.1.1-py3-none-any.whl (15.1MB)\n",
            "\u001b[K     |████████████████████████████████| 15.1MB 294kB/s \n",
            "\u001b[?25hCollecting importlib-resources>=1.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/03/0f9595c0c2ef12590877f3c47e5f579759ce5caf817f8256d5dcbd8a1177/importlib_resources-3.0.0-py2.py3-none-any.whl\n",
            "Collecting tqdm>=4.43.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/cf/f91813073e4135c1183cadf968256764a6fe4e35c351d596d527c0540461/tqdm-4.50.2-py2.py3-none-any.whl (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /usr/local/lib/python3.6/dist-packages (from sweetviz) (1.1.2)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from sweetviz) (2.11.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.6/dist-packages (from sweetviz) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=3.1.3 in /usr/local/lib/python3.6/dist-packages (from sweetviz) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from sweetviz) (1.18.5)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources>=1.2.0->sweetviz) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.11.1->sweetviz) (1.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.3->sweetviz) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.3->sweetviz) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.3->sweetviz) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (1.15.0)\n",
            "Installing collected packages: importlib-resources, tqdm, sweetviz\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed importlib-resources-3.0.0 sweetviz-1.1.1 tqdm-4.50.2\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.11.0)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (from imblearn) (0.4.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->imbalanced-learn->imblearn) (0.16.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.1.2)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->statsmodels) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->statsmodels) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.0->statsmodels) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxpadQ1MShjf"
      },
      "source": [
        "# Given Data Exploration and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYxYaT1b_J44"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style=\"white\")\n",
        "sns.set(style=\"whitegrid\", color_codes=True)\n",
        "\n",
        "#ler os dados\n",
        "df = pd.read_excel('dataset.xlsx')\n",
        "\n",
        "#imprimir as primeiras linhas do DataFrame\n",
        "df.head()\n",
        "\n",
        "#Para nosso objetivo a identificação do paciente não importa, então vamos deletar essa coluna\n",
        "del df['Patient ID']\n",
        "\n",
        "\n",
        "# vamos colocar todos os nomes das colunas em letras minúsculas\n",
        "df = df.rename(columns=str.lower)\n",
        "df.head()\n",
        "\n",
        "# vamos importar uma biblioteca que vai ajudar a ter uma visão geral do dados\n",
        "# https://pypi.org/project/sweetviz/\n",
        "\n",
        "import sweetviz as sv\n",
        "\n",
        "df['urine - ph'].replace('Não Realizado', 0.0000001 ,inplace=True)\n",
        "df['urine - ph'] = pd.to_numeric(df['urine - ph'], errors='coerce')\n",
        "\n",
        "advert_report = sv.analyze(df, pairwise_analysis='off')\n",
        "\n",
        "advert_report.show_html('Advertising.html')\n",
        "\n",
        "# Vamos criar uma função customizadas para realizar o EDA\n",
        "def EDA (df):\n",
        "\n",
        "    eda_df = {}\n",
        "    eda_df['Amount_NaN'] = df.isnull().sum()\n",
        "    eda_df['%_NaN'] = df.isnull().mean().round(2)\n",
        "    eda_df['DType'] = df.dtypes\n",
        "    eda_df['Amount_Data'] = df.count()\n",
        "\n",
        "    \n",
        "    eda_df['Mean'] = np.round(df.mean(), 2);\n",
        "    eda_df['Median'] = np.round(df.median(), 2);\n",
        "    \n",
        "    eda_df['Max'] = df.max()\n",
        "    eda_df['Min'] = df.min()\n",
        "    eda_df['STD'] = np.round(df.std(), 2)\n",
        "    \n",
        "    eda = pd.DataFrame(eda_df)\n",
        "    \n",
        "    colunas = sorted(df.columns.tolist(), reverse=False)\n",
        "    eda['Amount_Unique'] = list(map(lambda x: len(df[x].unique().tolist()), colunas))\n",
        "\n",
        "    return eda\n",
        "\n",
        "#Chamar a função criada acima para gerar o DataFrame\n",
        "informacao_df = EDA(df)\n",
        "\n",
        "#imprimir as primeiras linhas\n",
        "informacao_df.head()\n",
        "\n",
        "\n",
        "def gerar_graficos(df):\n",
        "    # definir a fonte utilizada nos gráficos\n",
        "    plt.rcParams['font.family'] = 'monospace'\n",
        "    plt.rcParams['font.monospace'] = 'Roboto Mono'\n",
        "\n",
        "    ax = df[\"%_NaN\"].value_counts(normalize=True).plot(kind=\"bar\", figsize=(20, 10), cmap='YlGnBu_r');\n",
        "\n",
        "    # título dos eixos\n",
        "    ax.set_xlabel(\"% de dados faltantes\", fontsize=26)\n",
        "    ax.set_ylabel(\"% de colunas\", fontsize=26)\n",
        "\n",
        "    # tick labels.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",\n",
        "             rotation_mode=\"anchor\", fontsize=20);\n",
        "\n",
        "    plt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\",\n",
        "             rotation_mode=\"anchor\", fontsize=20);\n",
        "\n",
        "    # título do gráfico\n",
        "    plt.title(\"Dados Faltantes - COVID19 DataSet\", fontsize=28);\n",
        "\n",
        "    return (plt.show())\n",
        "\n",
        "#Vamos começar olhando para as coluna com dados faltantes\n",
        "gerar_graficos(informacao_df);\n",
        "\n",
        "#Deletar as colunas com aproximadamente 100% de dados faltantes\n",
        "\n",
        "#Seleção das colunas\n",
        "del_colunas = informacao_df.loc[informacao_df[\"%_NaN\"] == 1].index.tolist()\n",
        "\n",
        "#Deletar as colunas\n",
        "df1 = df.drop(columns = del_colunas)\n",
        "\n",
        "# vamos ver quais colunas foram excluídas\n",
        "del_colunas\n",
        "\n",
        "#Recriar o DataFrame com as informações do novo dataset\n",
        "informacao_df1 = EDA(df1)\n",
        "\n",
        "gerar_graficos(informacao_df1);\n",
        "\n",
        "#Vamos Analisar um pouco mais as colunas com muitos dados faltantes (Acima de 90%), que são categóricas\n",
        "cols = informacao_df1.loc[(informacao_df1[\"DType\"]==\"object\") \\\n",
        "                             & (informacao_df1[\"%_NaN\"]>=0.9)].index.tolist()\n",
        "\n",
        "#Vamos imprimir as colunas e seus valores únicos\n",
        "for col in cols:\n",
        "    print (col,\"  \",df[col].unique().tolist())\n",
        "    print (\"\\n\")\n",
        "\n",
        "#Considerando que as colunas acima estão associadas à urina, é bem provável que não seja muito relevante para nosso\n",
        "#objetivo. Dessa maneira podemos excluir essas colunas sem perda alguma de informação\n",
        "df2 = df1.drop(columns=cols)\n",
        "\n",
        "#Recriar o DataFrame com as informações do novo dataset\n",
        "informacao_df2 = EDA(df2)\n",
        "\n",
        "gerar_graficos(informacao_df2);\n",
        "\n",
        "#Para tentarmos entender melhor as colunas, vamos olhar com mais carinho apenas pacientes com COVID\n",
        "df2_positivos = df2.loc[df2[\"sars-cov-2 exam result\"]==\"positive\"]\n",
        "\n",
        "#vamos gerar as informações somente dos pacientes com COVID-19\n",
        "informacao_df2 = EDA(df2_positivos)\n",
        "\n",
        "gerar_graficos(informacao_df2);\n",
        "\n",
        "#Vamos Analisar um pouco mais as colunas quando selecionamos apenas casos positivos para COVID-19\n",
        "cols = informacao_df2.loc[(informacao_df2[\"Amount_Unique\"]== 2) & \\\n",
        "                          (informacao_df2[\"DType\"]== \"object\") ].index.tolist()\n",
        "\n",
        "#cols.remove(\"sars-cov-2 exam result\")\n",
        "\n",
        "for col in cols:\n",
        "    if (len(df2_positivos[col].unique().tolist()) ==2):\n",
        "        print (col,\"  \", df2_positivos[col].unique().tolist())\n",
        "        print (\"\\n\")\n",
        "\n",
        "#Excluir as colunas acima\n",
        "df3 = df2.drop(columns=cols)\n",
        "\n",
        "df3.shape\n",
        "\n",
        "#Recriar o DataFrame com as informações do novo dataset\n",
        "informacao_df3 = EDA(df3)\n",
        "\n",
        "gerar_graficos(informacao_df3);\n",
        "\n",
        "#Após essa limpeza inicial (na qual buscamos entender o significado das colunas excluídas), vamos retirar\n",
        "#as colunas do tipo float que apresentam muitos dados faltantes\n",
        "\n",
        "cols = informacao_df3.loc[(informacao_df3[\"%_NaN\"]> 0.95) & (informacao_df3[\"DType\"] == \"float\")].index.tolist()\n",
        "\n",
        "df4 = df3.drop(columns=cols)\n",
        "\n",
        "#Vamos conferir como esta o conjunto de dados nesse ponto da limpeza de dados\n",
        "informacao_df4 = EDA(df4)\n",
        "\n",
        "gerar_graficos(informacao_df4);\n",
        "\n",
        "#Vamos excluir linhas que apresentam mas de 50% dos dados faltantes\n",
        "df5 = df4.dropna(thresh = int(df4.shape[1]*0.5))\n",
        "df4.shape\n",
        "\n",
        "df5.shape\n",
        "\n",
        "#Atualizando as informações do dataset\n",
        "informacao_df5 = EDA(df5)\n",
        "\n",
        "gerar_graficos(informacao_df5);\n",
        "\n",
        "#Vamos Analisar um pouco mais as colunas com muitos dados faltantes\n",
        "cols = informacao_df5.loc[(informacao_df5[\"%_NaN\"]==0.67) & (informacao_df5[\"DType\"]!= \"int64\") ].index.tolist()\n",
        "cols\n",
        "\n",
        "#vamos selecionar as colunas que apresentam Influenza no nome\n",
        "influenza_b_cols = df5.loc[:, df5.columns.str.startswith('influenza')].columns.tolist()\n",
        "influenza_b_cols\n",
        "\n",
        "df6 = df5.drop(columns=influenza_b_cols, axis=1)\n",
        "\n",
        "#Atualizar as informações do data set\n",
        "informacao_df6 = EDA(df6)\n",
        "\n",
        "\n",
        "gerar_graficos(informacao_df6);\n",
        "\n",
        "#vamos ver as colunas que apresentam mais dados faltantes\n",
        "cols = informacao_df6.loc[(informacao_df6[\"%_NaN\"] == 0.39) & (informacao_df6[\"DType\"]== \"object\") ].index.tolist()\n",
        "cols\n",
        "\n",
        "#como são exames relacionadas à outras doenças vamos exclui-las\n",
        "df7 = df6.drop(columns=cols)\n",
        "\n",
        "#Atualizar as informações do data set\n",
        "informacao_df7 = EDA(df7)\n",
        "\n",
        "gerar_graficos(informacao_df7);\n",
        "\n",
        "#Vamos ver as informações que contém nas colunas que apresentam mais de 30% de dados faltantes\n",
        "cols = informacao_df7.loc[(informacao_df7[\"%_NaN\"] >= 0.3)].index.tolist()\n",
        "cols\n",
        "\n",
        "#No primeiro instante não parecem informações relevantes para nosso objetivo\n",
        "df8 = df7.drop(columns=cols)\n",
        "\n",
        "#Atualizar as informações sobre o dataset\n",
        "informacao_df8 = EDA(df8)\n",
        "\n",
        "gerar_graficos(informacao_df8);\n",
        "\n",
        "df9 = df8.fillna(df8.median())\n",
        "\n",
        "#Atualizar as informações sobre o dataset\n",
        "informacao_df9 = EDA(df9)\n",
        "# \n",
        "gerar_graficos(informacao_df9);\n",
        "\n",
        "informacao_df9\n",
        "\n",
        "print(\"------------\" * 3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDPxnbgGSwwS"
      },
      "source": [
        "# My Turn\n",
        "\n",
        "*`Escrevi minhas notas e análises em inglês, pois vivi a maior parte da minha vida no Reino Unido e acho mais eficiente me expressar dessa forma.`*\n",
        "\n",
        "Initially, I decided to visualize what we can learn from the entire dataset after applying a Logistic Regression. Using oversampling I achieved a confusion matrix which did not perform adequately. It did well when predicting positive test results however about half of the positive test results returned as false negatives. Which for the needs of this analysis is a poor performance as we could potentially misinform people who have contracted the virus which is the worst case scenario. Our model is too generous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fEMzlt6Suth",
        "outputId": "f9e39da3-02c1-4ed6-e344-a4c1d1015709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "df9.head()\n",
        "\n",
        "data_final=df9.copy()\n",
        "data_final.columns.values\n",
        "\n",
        "print(df9.values)\n",
        "\n",
        "X = data_final.loc[:, data_final.columns != 'sars-cov-2 exam result']\n",
        "Y = data_final.loc[:, data_final.columns == 'sars-cov-2 exam result']\n",
        "\n",
        "# print('---------', ' save to mat file ', '------------')\n",
        "\n",
        "# for key in data_final:\n",
        "#   if len(key) > 29:\n",
        "#     new_key = key\\\n",
        "#       .replace(' (1=yes, 0=no)', '')\\\n",
        "#       .replace('patient addmited to ','')\\\n",
        "#       .replace('mean corpuscular ', 'mc ')\\\n",
        "#       .replace('red blood cell ','rbc ')\\\n",
        "#       .replace('hemoglobin ', 'h ')\\\n",
        "#       .replace('distribution weight', 'dw')\\\n",
        "#       .replace('reativa', 'rea').encode('utf-8')\n",
        "#     data_final[new_key] = data_final[key]\n",
        "#     del data_final[key]\n",
        "\n",
        "# for key in data_final:\n",
        "#   print(key)\n",
        "# import scipy.io\n",
        "\n",
        "# scipy.io.savemat('arrdata.mat', mdict={'X': data_final})\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "os = SMOTE(random_state=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "columns = X_train.columns\n",
        "\n",
        "os_data_X, os_data_y=os.fit_sample(X_train, y_train)\n",
        "os_data_X = pd.DataFrame(data=os_data_X, columns=columns)\n",
        "os_data_y = pd.DataFrame(data=os_data_y, columns=['sars-cov-2 exam result'])\n",
        "# check numbers for our data\n",
        "# print(\"data: \", os_data_X, os_data_y)\n",
        "print(\"length of oversampled data is \",len(os_data_X))\n",
        "print(\"Number of negative patients in oversampled data\",len(os_data_y[os_data_y['sars-cov-2 exam result']=='negative']))\n",
        "print(\"Number of positive\",len(os_data_y[os_data_y['sars-cov-2 exam result']=='positive']))\n",
        "print(\"Proportion of negative patient data in oversampled data is \",len(os_data_y[os_data_y['sars-cov-2 exam result']=='negative'])/len(os_data_X))\n",
        "print(\"Proportion of positive patient data in oversampled data is \",len(os_data_y[os_data_y['sars-cov-2 exam result']=='positive'])/len(os_data_X))\n",
        "\n",
        "# print(\"---------\" *2, \" recursive feature elimination \", \"--------\" * 2)\n",
        "\n",
        "# data_final_vars=data_final.columns.values.tolist()\n",
        "# y=['y']\n",
        "# X=[i for i in data_final_vars if i not in y]\n",
        "# from sklearn.feature_selection import RFE\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# logreg = LogisticRegression()\n",
        "# rfe = RFE(logreg, 20)\n",
        "# rfe = rfe.fit(os_data_X, os_data_y.values.ravel())\n",
        "# print(rfe.support_)\n",
        "# print(rfe.ranking_)\n",
        "\n",
        "\n",
        "print(\"----------\" * 2, \" model \", \"-------\" * 2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}%'.format(100 * (logreg.score(X_test, y_test))))\n",
        "# print(logreg)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[17 'negative' 0 ... -0.6250726580619812 -0.6190860271453857\n",
            "  -0.147894948720932]\n",
            " [1 'negative' 0 ... -0.9788991212844849 -0.127395361661911\n",
            "  -0.2869857549667358]\n",
            " [9 'negative' 0 ... -1.067355036735535 0.880570113658905\n",
            "  -0.3932908624410629]\n",
            " ...\n",
            " [15 'negative' 0 ... -1.155811905860901 -0.06183667480945587\n",
            "  0.5614683032035828]\n",
            " [17 'negative' 0 ... -0.4481598734855652 1.552547812461853\n",
            "  0.609156608581543]\n",
            " [19 'positive' 0 ... -0.1827902793884277 0.3806847631931305\n",
            "  -0.503570020198822]]\n",
            "length of oversampled data is  724\n",
            "Number of negative patients in oversampled data 362\n",
            "Number of positive 362\n",
            "Proportion of negative patient data in oversampled data is  0.5\n",
            "Proportion of positive patient data in oversampled data is  0.5\n",
            "--------------------  model  --------------\n",
            "Accuracy of logistic regression classifier on test set: 91.71%\n",
            "[[156   1]\n",
            " [ 14  10]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUustiC1UHN0"
      },
      "source": [
        "# Further Filtering\n",
        "\n",
        "Clearly my initial approach was ambitious. I need to make a more in depth attempt at determining what features are potentially relevant to the contraction of the virus and could be more efficient in teaching us about the problem.\n",
        "\n",
        "The following analysis is based on the idea that blood related features could potentially be more insightful. Considering that the main identifiers regarding our immune system and oxygen levels are found in our blood stream.\n",
        "\n",
        "This however, provided us with a far less performant model, with more false negatives and less true positives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyQFOfRwUwwP",
        "outputId": "eb3c807e-f979-4014-9cb3-3c544cdc08a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "\n",
        "# with bloodcell related features\n",
        "blood_df = data_final.copy()\n",
        "del blood_df['patient age quantile']\n",
        "del blood_df['proteina c reativa mg/dl']\n",
        "del blood_df['patient addmited to regular ward (1=yes, 0=no)']\n",
        "del blood_df['patient addmited to semi-intensive unit (1=yes, 0=no)']\n",
        "del blood_df['patient addmited to intensive care unit (1=yes, 0=no)']\n",
        "\n",
        "X = blood_df.loc[:, blood_df.columns != 'sars-cov-2 exam result']\n",
        "Y = blood_df.loc[:, blood_df.columns == 'sars-cov-2 exam result']\n",
        "\n",
        "print(\"----------\" * 2, \" model \", \"-------\" * 2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}%'.format(100 * (logreg.score(X_test, y_test))))\n",
        "# print(logreg)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------  model  --------------\n",
            "Accuracy of logistic regression classifier on test set: 86.74%\n",
            "[[153   4]\n",
            " [ 20   4]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVXGZmNNdhzW"
      },
      "source": [
        "# More specific Identifiers\n",
        "\n",
        "Perhaps we must again filter the more specifically related features in order to acheive a more performant model. I also decided to migrate from the Logistic Regression approach considering the model so far has been provide us with a high level of false negatives.\n",
        "\n",
        "Evidently, the Naive Bayse model is closer to the desired result though still lack luster. While the count of true positives has reduced, we have brought our false negatives under control and can look to improve on this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_nSikp9dxnQ",
        "outputId": "c2ca372f-8e66-42f2-8670-203b0d7629d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "\n",
        "# with bloodcell related features\n",
        "blood_oxygen_df = data_final.copy()\n",
        "del blood_oxygen_df['patient age quantile']\n",
        "del blood_oxygen_df['patient addmited to regular ward (1=yes, 0=no)']\n",
        "del blood_oxygen_df['patient addmited to semi-intensive unit (1=yes, 0=no)']\n",
        "del blood_oxygen_df['patient addmited to intensive care unit (1=yes, 0=no)']\n",
        "del blood_oxygen_df['mean corpuscular volume (mcv)']\n",
        "\n",
        "print(blood_oxygen_df.columns)\n",
        "\n",
        "X = blood_oxygen_df.loc[:, blood_oxygen_df.columns != 'sars-cov-2 exam result']\n",
        "Y = blood_oxygen_df.loc[:, blood_oxygen_df.columns == 'sars-cov-2 exam result']\n",
        "\n",
        "\n",
        "print(\"----------\" * 2, \" model \", \"-------\" * 2)\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = nb.predict(X_test)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}%'.format(100 * (nb.score(X_test, y_test))))\n",
        "# print(logreg)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['sars-cov-2 exam result', 'hematocrit', 'hemoglobin', 'platelets',\n",
            "       'mean platelet volume ', 'red blood cells', 'lymphocytes',\n",
            "       'mean corpuscular hemoglobin concentration (mchc)', 'leukocytes',\n",
            "       'basophils', 'mean corpuscular hemoglobin (mch)', 'eosinophils',\n",
            "       'monocytes', 'red blood cell distribution width (rdw)', 'neutrophils',\n",
            "       'proteina c reativa mg/dl'],\n",
            "      dtype='object')\n",
            "--------------------  model  --------------\n",
            "Accuracy of logistic regression classifier on test set: 87.85%\n",
            "[[143  14]\n",
            " [  8  16]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7ReXhsKivpz"
      },
      "source": [
        "# Imunity\n",
        "\n",
        "Perhaps features related to imunity can provide us with some significant insight. This approach has provided us with more reasonable predictions though perhaps more data and exploration is needed to come to a solid conclusion. I applied an oversampling of the data, achieving a more even distribution of results.\n",
        "\n",
        "This approach has clearly provided us with more cohessive predictions, though there is still much to be improved on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC1T7ovrhq4i",
        "outputId": "e4e26088-ecc0-418d-e8bc-e30ebd7f92f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "imunity = data_final.copy()\n",
        "\n",
        "del imunity['patient addmited to regular ward (1=yes, 0=no)']\n",
        "del imunity['patient addmited to semi-intensive unit (1=yes, 0=no)']\n",
        "del imunity['hematocrit']\n",
        "del imunity['red blood cells']\n",
        "del imunity['red blood cell distribution width (rdw)']\n",
        "del imunity['patient addmited to intensive care unit (1=yes, 0=no)']\n",
        "\n",
        "\n",
        "X = imunity.loc[:, imunity.columns != 'sars-cov-2 exam result']\n",
        "Y = imunity.loc[:, imunity.columns == 'sars-cov-2 exam result']\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "os = SMOTE(random_state=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "columns = X_train.columns\n",
        "\n",
        "os_data_X, os_data_y=os.fit_sample(X_train, y_train)\n",
        "os_data_X = pd.DataFrame(data=os_data_X, columns=columns)\n",
        "os_data_y = pd.DataFrame(data=os_data_y, columns=['sars-cov-2 exam result'])\n",
        "\n",
        "print(\"length of oversampled data is \",len(os_data_X))\n",
        "print(\"Number of negative patients in oversampled data\",len(os_data_y[os_data_y['sars-cov-2 exam result']=='negative']))\n",
        "print(\"Number of positive\",len(os_data_y[os_data_y['sars-cov-2 exam result']=='positive']))\n",
        "print(\"Proportion of negative patient data in oversampled data is \",len(os_data_y[os_data_y['sars-cov-2 exam result']=='negative'])/len(os_data_X))\n",
        "print(\"Proportion of positive patient data in oversampled data is \",len(os_data_y[os_data_y['sars-cov-2 exam result']=='positive'])/len(os_data_X))\n",
        "\n",
        "\n",
        "print(\"----------\" * 2, \" model \", \"-------\" * 2)\n",
        "\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = nb.predict(X_test)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}%'.format(100 * (nb.score(X_test, y_test))))\n",
        "# print(logreg)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of oversampled data is  724\n",
            "Number of negative patients in oversampled data 362\n",
            "Number of positive 362\n",
            "Proportion of negative patient data in oversampled data is  0.5\n",
            "Proportion of positive patient data in oversampled data is  0.5\n",
            "--------------------  model  --------------\n",
            "Accuracy of logistic regression classifier on test set: 90.06%\n",
            "[[148   9]\n",
            " [  9  15]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uaHeYc-G__p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlUshW05G3ig"
      },
      "source": [
        "# Notes\n",
        "\n",
        "- My impression is that this dataset is not particularly effective in helping us understand the tendencies of the Covid19 virus. Most likely this can be attributed to my limitations as an analyser of the data provided as well as my limited knowledge of potential models to apply and how to apply them.\n",
        "- With that said, it was a great learning experience and I definately feel that I have advanced significantly in this discipline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1qMvPsVHKm3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}